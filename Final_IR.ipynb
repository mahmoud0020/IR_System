{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# pakage to convert corps to token\n",
    "from nltk.tokenize import word_tokenize\n",
    "# pakage to remove any stop word \n",
    "from nltk.corpus import stopwords\n",
    "# pakage to make lemmataiztion\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# pakage to make stemming of token  \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------#\n",
    "#---------- Preprocessing Section -------------#\n",
    "\n",
    "# this function is remove stop words like (a ,an ,the ,is , are, etc ...)\n",
    "# def remove_stop_words(tokens):\n",
    "#     stop_words =set(stopwords.words('english'))\n",
    "#     result_tokens = []\n",
    "#     for token in tokens:\n",
    "#         if token not in stop_words:\n",
    "#             result_tokens.append(token)\n",
    "#     return result_tokens\n",
    "#---------------------------------------------#\n",
    "# applay of each token stemming and lemmtizing method\n",
    "def stemming_lemmitization(tokens):\n",
    "    stemmer =PorterStemmer()\n",
    "    lemmatizer =WordNetLemmatizer()\n",
    "    result_tokens =[]\n",
    "    for token in tokens:\n",
    "        token =lemmatizer.lemmatize(token)\n",
    "        # token = stemmer.stem(token)\n",
    "        if len(token) > 1:\n",
    "            result_tokens.append(token)\n",
    "    return result_tokens\n",
    "#---------------------------------------------#\n",
    "# this function is remove any pattern of link or email or \\n and etc ...\n",
    "def removePatterns(corpus):    \n",
    "    patterns = ['URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m']\n",
    "    for pattern in patterns:\n",
    "        corpus = corpus.replace(pattern, '')\n",
    "    return re.sub(r'[^a-zA-Z]', ' ', corpus)\n",
    "#---------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.txt', '1.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', '7.txt', '8.txt', '9.txt']\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------#\n",
    "#---------- print document in files ----------#\n",
    "dirFiles = os.listdir('C:\\\\Users\\\\mahmoud0020\\\\Desktop\\\\IR_Final\\\\DataSets\\\\')\n",
    "# print(sorted(dirFiles))\n",
    "print(dirFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['antony', 'brutus', 'caeser', 'calpurnia']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['mercy', 'worser']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['brutus', 'caeser', 'mercy', 'worser']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['caeser', 'mercy', 'worser']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['antony', 'caeser', 'mercy']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where']\n",
      "---------------------------------------------------------------------------------------------\n",
      "['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------Read Document Collection -----------#\n",
    "# read files from disk\n",
    "dirFiles = os.listdir('C:\\\\Users\\\\mahmoud0020\\\\Desktop\\\\IR_Final\\\\DataSets');\n",
    "list_of_corpus =[]\n",
    "result_tokens =[]\n",
    "for file in dirFiles :\n",
    "    single_file =open('C:\\\\Users\\\\mahmoud0020\\\\Desktop\\\\IR_Final\\\\DataSets\\\\'+file,'r');\n",
    "    for line in single_file:\n",
    "        \n",
    "        list_of_corpus.append(line)\n",
    "        # remove any pattern like URL or Email or etc...\n",
    "        corpus = removePatterns(line)\n",
    "        # convert corpus to tokens \n",
    "        corpus = word_tokenize(corpus.lower())\n",
    "        # remove stop_words like (a- and -the or etc...)\n",
    "#         tokens = remove_stop_words(corpus)\n",
    "        # make stemming and lemmitization of tokens \n",
    "        tokens = stemming_lemmitization(corpus)\n",
    "        # save result of tokens \n",
    "        result_tokens.append(tokens)\n",
    "    single_file.close()\n",
    "print(len(result_tokens))\n",
    "for i in range(len(result_tokens)):\n",
    "    print(result_tokens[i])\n",
    "    print(\"---------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Index\n",
      "[Term { docID : [Postion]}]\n",
      "[4, {0: [5], 2: [1], 3: [3], 4: [2]}]\n",
      "Filename, [Positions]\n",
      "0.txt     [5]\n",
      "2.txt     [1]\n",
      "3.txt     [3]\n",
      "4.txt     [2]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------#\n",
    "#-------------- Positional Index --------------#\n",
    "fileNumber = 0;\n",
    "# this is dictionary structure \n",
    "postional_index ={}\n",
    "# the file mapping (fileNumber -->{ file name })\n",
    "file_map={}\n",
    "\n",
    "for corpus in result_tokens:\n",
    "    for postion,term in enumerate(corpus):\n",
    "        # check if the term already exists in the positonal index dictionary.\n",
    "        if term in postional_index:\n",
    "            # increment total frequency by 1 \n",
    "            postional_index[term][0] = postional_index[term][0]+1\n",
    "            # check if the term has found in DocumentID before\n",
    "            if fileNumber in postional_index[term][1]:\n",
    "                postional_index[term][1][fileNumber].append(postion)\n",
    "            else:\n",
    "                postional_index[term][1][fileNumber]=[postion]\n",
    "        # if the term does not exist in the postional index dictionary \n",
    "        # (first encounter)\n",
    "        else:\n",
    "            # empty the list \n",
    "            postional_index[term]=[]\n",
    "            # total frequency is 1 \n",
    "            postional_index[term].append(1)\n",
    "            # the posting list is intially empty \n",
    "            postional_index[term].append({})\n",
    "            # add document ID to posting list.\n",
    "            postional_index[term][1][fileNumber]=[postion]\n",
    "    # map the filenumber to the filename.\n",
    "    file_map[fileNumber] = corpus\n",
    "    # increment file number to next document \n",
    "    fileNumber+=1\n",
    "#-----print result of Postional index -----#\n",
    "sample_pos_idx = postional_index[\"worser\"]\n",
    "print(\"Positional Index\") \n",
    "print(\"[Term { docID : [Postion]}]\")\n",
    "print(sample_pos_idx) \n",
    "sampe_pos_idx =postional_index[\"angel\"]\n",
    "file_list = sample_pos_idx[1] \n",
    "\n",
    "print(\"Filename, [Positions]\") \n",
    "for fileno, positions in file_list.items(): \n",
    "    print(dirFiles[fileno],\"   \", positions)   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc0 = result_tokens[0]\n",
    "doc1 = result_tokens[1]\n",
    "doc2 = result_tokens[2]\n",
    "doc3 = result_tokens[3]\n",
    "doc4 = result_tokens[4]\n",
    "doc5 = result_tokens[5]\n",
    "doc6 = result_tokens[6]\n",
    "doc7 = result_tokens[7]\n",
    "doc8 = result_tokens[8]\n",
    "doc9 = result_tokens[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antony', 'brutus', 'caeser', 'calpurnia']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(doc0).union(set(doc1)).union(set(doc2)).union(set(doc3)).union(set(doc4)).union(set(doc5)).union(set(doc6)).union(set(doc7)).union(set(doc8)).union(set(doc9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rush', 'antony', 'worser', 'cleopatra', 'brutus', 'calpurnia', 'to', 'where', 'caeser', 'fear', 'fool', 'in', 'tread', 'angel', 'mercy'}\n"
     ]
    }
   ],
   "source": [
    "print(wordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want set each token with dictionary zero value \n",
    "wordDict0 = dict.fromkeys(wordSet, 0) \n",
    "wordDict1 = dict.fromkeys(wordSet, 0)\n",
    "wordDict2 = dict.fromkeys(wordSet, 0) \n",
    "wordDict3 = dict.fromkeys(wordSet, 0)\n",
    "wordDict4 = dict.fromkeys(wordSet, 0) \n",
    "wordDict5 = dict.fromkeys(wordSet, 0)\n",
    "wordDict6 = dict.fromkeys(wordSet, 0) \n",
    "wordDict7 = dict.fromkeys(wordSet, 0)\n",
    "wordDict8 = dict.fromkeys(wordSet, 0) \n",
    "wordDict9 = dict.fromkeys(wordSet, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the value of term if found in another document\n",
    "#----------------------compute TF ---------------------#\n",
    "for word in doc0:\n",
    "    wordDict0[word]+=1\n",
    "    \n",
    "for word in doc1:\n",
    "    wordDict1[word]+=1\n",
    "\n",
    "for word in doc2:\n",
    "    wordDict2[word]+=1\n",
    "    \n",
    "for word in doc3:\n",
    "    wordDict3[word]+=1\n",
    "    \n",
    "for word in doc4:\n",
    "    wordDict4[word]+=1\n",
    "\n",
    "for word in doc5:\n",
    "    wordDict5[word]+=1\n",
    "    \n",
    "for word in doc6:\n",
    "    wordDict6[word]+=1\n",
    "\n",
    "for word in doc7:\n",
    "    wordDict7[word]+=1\n",
    "    \n",
    "for word in doc8:\n",
    "    wordDict8[word]+=1\n",
    "\n",
    "for word in doc9:\n",
    "    wordDict9[word]+=1\n",
    "\n",
    "# for word in query_tokens:\n",
    "#     queryDict[word]+=1\n",
    "# for word in wordSet:\n",
    "#     for token in query_tokens:\n",
    "#         if(token==word):\n",
    "#             QueryDict[word]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4  5  6  7  8  9\n",
       "rush       0  0  0  0  0  0  1  1  1  1\n",
       "antony     1  1  0  0  0  1  0  0  0  0\n",
       "worser     1  0  1  1  1  0  0  0  0  0\n",
       "cleopatra  1  0  0  0  0  0  0  0  0  0\n",
       "brutus     1  1  0  1  0  0  0  0  0  0\n",
       "calpurnia  0  1  0  0  0  0  0  0  0  0\n",
       "to         0  0  0  0  0  0  1  1  1  1\n",
       "where      0  0  0  0  0  0  1  1  1  1\n",
       "caeser     1  1  0  1  1  1  0  0  0  0\n",
       "fear       0  0  0  0  0  0  1  1  0  1\n",
       "fool       0  0  0  0  0  0  1  1  1  1\n",
       "in         0  0  0  0  0  0  1  1  1  1\n",
       "tread      0  0  0  0  0  0  1  1  1  1\n",
       "angel      0  0  0  0  0  0  1  1  1  0\n",
       "mercy      1  0  1  1  1  1  0  0  0  0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([wordDict0, wordDict1, wordDict2, wordDict3, wordDict4, wordDict5, wordDict6, wordDict7, wordDict8, wordDict9]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------compute TF_weight-----------------#\n",
    "import math\n",
    "for word in doc0:\n",
    "    if(wordDict0[word]>0):\n",
    "        wordDict0[word]=1+math.log(wordDict0[word],10)\n",
    "    \n",
    "        \n",
    "for word in doc1:\n",
    "    if(wordDict1[word]>0):\n",
    "        wordDict1[word]=1+math.log(wordDict1[word],10)\n",
    "    \n",
    "\n",
    "for word in doc2:\n",
    "    if(wordDict2[word]>0):\n",
    "        wordDict2[word]=1+math.log(wordDict2[word],10)\n",
    "   \n",
    "    \n",
    "for word in doc3:\n",
    "    if(wordDict3[word]>0):\n",
    "        wordDict3[word]=1+math.log(wordDict3[word],10)\n",
    "    \n",
    "    \n",
    "for word in doc4:\n",
    "    if(wordDict4[word]>0):\n",
    "        wordDict4[word]=1+math.log(wordDict4[word],10)\n",
    "    \n",
    "\n",
    "for word in doc5:\n",
    "    if(wordDict5[word]>0):\n",
    "        wordDict5[word]=1+math.log(wordDict5[word],10)\n",
    "\n",
    "for word in doc6:\n",
    "    if(wordDict6[word]>0):\n",
    "        wordDict6[word]=1+math.log(wordDict6[word],10)\n",
    "        \n",
    "for word in doc7:\n",
    "    if(wordDict7[word]>0):\n",
    "        wordDict7[word]=1+math.log(wordDict7[word],10)\n",
    "    \n",
    "for word in doc8:\n",
    "    if(wordDict8[word]>0):\n",
    "        wordDict8[word]=1+math.log(wordDict8[word],10)\n",
    "\n",
    "for word in doc9:\n",
    "    if(wordDict9[word]>0):\n",
    "        wordDict9[word]=1+math.log(wordDict9[word],10)\n",
    "# for word in query_tokens:\n",
    "#     if(QueryDict[word]>0):\n",
    "#         QueryDict[word]=1+math.log(QueryDict[word],10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9\n",
       "rush       0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "antony     1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "worser     1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "cleopatra  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "brutus     1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "calpurnia  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "to         0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "where      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "caeser     1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       "fear       0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0\n",
       "fool       0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "in         0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "tread      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
       "angel      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0\n",
       "mercy      1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([wordDict0, wordDict1, wordDict2, wordDict3, wordDict4, wordDict5, wordDict6, wordDict7, wordDict8, wordDict9]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 4, 1, 3, 1, 4, 4, 5, 3, 4, 4, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "#------------------Compute IDF ---------------------#\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    # -----compute Document Frequency ------ #\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "# #----------------compute DF -------------------------#\n",
    "def Compute_DF(term,postional_index):\n",
    "    result=[]\n",
    "    for i in term.keys():\n",
    "        try:\n",
    "            \n",
    "            sample_pos_idx =postional_index[i]\n",
    "            result.append(len(sample_pos_idx[1].values()))\n",
    "        except:\n",
    "            None\n",
    "    return result\n",
    "\n",
    "result_Document_Freq =Compute_DF(wordDict0,postional_index)\n",
    "\n",
    "print(result_Document_Freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDict0, wordDict1, wordDict2, wordDict3, wordDict4, wordDict5, wordDict6, wordDict7, wordDict8, wordDict9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rush': 0.3979400086720376, 'antony': 0.5228787452803376, 'worser': 0.3979400086720376, 'cleopatra': 1.0, 'brutus': 0.5228787452803376, 'calpurnia': 1.0, 'to': 0.3979400086720376, 'where': 0.3979400086720376, 'caeser': 0.3010299956639812, 'fear': 0.5228787452803376, 'fool': 0.3979400086720376, 'in': 0.3979400086720376, 'tread': 0.3979400086720376, 'angel': 0.5228787452803376, 'mercy': 0.3010299956639812}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF</th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>5</td>\n",
       "      <td>0.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>4</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>5</td>\n",
       "      <td>0.301030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DF       IDF\n",
       "rush        4  0.397940\n",
       "antony      3  0.522879\n",
       "worser      4  0.397940\n",
       "cleopatra   1  1.000000\n",
       "brutus      3  0.522879\n",
       "calpurnia   1  1.000000\n",
       "to          4  0.397940\n",
       "where       4  0.397940\n",
       "caeser      5  0.301030\n",
       "fear        3  0.522879\n",
       "fool        4  0.397940\n",
       "in          4  0.397940\n",
       "tread       4  0.397940\n",
       "angel       3  0.522879\n",
       "mercy       5  0.301030"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(idfs)\n",
    "pd.DataFrame(list(zip( result_Document_Freq,idfs.values())),index=idfs.keys(),columns =['DF', 'IDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF_IDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_Idf_Bow0 = computeTF_IDF(wordDict0, idfs)\n",
    "TF_Idf_Bow1 = computeTF_IDF(wordDict1, idfs)\n",
    "TF_Idf_Bow2 = computeTF_IDF(wordDict2, idfs)\n",
    "TF_Idf_Bow3 = computeTF_IDF(wordDict3, idfs)\n",
    "TF_Idf_Bow4 = computeTF_IDF(wordDict4, idfs)\n",
    "TF_Idf_Bow5 = computeTF_IDF(wordDict5, idfs)\n",
    "TF_Idf_Bow6 = computeTF_IDF(wordDict6, idfs)\n",
    "TF_Idf_Bow7 = computeTF_IDF(wordDict7, idfs)\n",
    "TF_Idf_Bow8 = computeTF_IDF(wordDict8, idfs)\n",
    "TF_Idf_Bow9 = computeTF_IDF(wordDict9, idfs)\n",
    "# TF_IDF_Query= computeTF_IDF(QueryDict, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1        2         3        4         5         6  \\\n",
       "rush       0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "antony     0.522879  0.522879  0.00000  0.000000  0.00000  0.522879  0.000000   \n",
       "worser     0.397940  0.000000  0.39794  0.397940  0.39794  0.000000  0.000000   \n",
       "cleopatra  1.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "brutus     0.522879  0.522879  0.00000  0.522879  0.00000  0.000000  0.000000   \n",
       "calpurnia  0.000000  1.000000  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "to         0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "where      0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "caeser     0.301030  0.301030  0.00000  0.301030  0.30103  0.301030  0.000000   \n",
       "fear       0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.522879   \n",
       "fool       0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "in         0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "tread      0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.397940   \n",
       "angel      0.000000  0.000000  0.00000  0.000000  0.00000  0.000000  0.522879   \n",
       "mercy      0.301030  0.000000  0.30103  0.301030  0.30103  0.301030  0.000000   \n",
       "\n",
       "                  7         8         9  \n",
       "rush       0.397940  0.397940  0.397940  \n",
       "antony     0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  \n",
       "brutus     0.000000  0.000000  0.000000  \n",
       "calpurnia  0.000000  0.000000  0.000000  \n",
       "to         0.397940  0.397940  0.397940  \n",
       "where      0.397940  0.397940  0.397940  \n",
       "caeser     0.000000  0.000000  0.000000  \n",
       "fear       0.522879  0.000000  0.522879  \n",
       "fool       0.397940  0.397940  0.397940  \n",
       "in         0.397940  0.397940  0.397940  \n",
       "tread      0.397940  0.397940  0.397940  \n",
       "angel      0.522879  0.522879  0.000000  \n",
       "mercy      0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------compute DF(Term Document frequency )------------------#\n",
    "pd.DataFrame([TF_Idf_Bow0, TF_Idf_Bow1, TF_Idf_Bow2, TF_Idf_Bow3, TF_Idf_Bow4, TF_Idf_Bow5, TF_Idf_Bow6, TF_Idf_Bow7,\n",
    "              TF_Idf_Bow8, TF_Idf_Bow9]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.373462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.279618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.582747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.674270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.223496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.223496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.106137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.106137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_Length\n",
       "0         1.373462\n",
       "1         1.279618\n",
       "2         0.498974\n",
       "3         0.782941\n",
       "4         0.582747\n",
       "5         0.674270\n",
       "6         1.223496\n",
       "7         1.223496\n",
       "8         1.106137\n",
       "9         1.106137"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------compute Document lenght-----------#\n",
    "import math\n",
    "def Get_lenght_Document(TF_IDF_values):\n",
    "    sum_val=0\n",
    "    temp=list(TF_IDF_values.values())\n",
    "    for i in range(len(temp)):\n",
    "        sum_val+=pow(temp[i],2)\n",
    "    return math.sqrt(sum_val)\n",
    "\n",
    "d0_lenght= Get_lenght_Document(TF_Idf_Bow0)\n",
    "d1_lenght= Get_lenght_Document(TF_Idf_Bow1)\n",
    "d2_lenght= Get_lenght_Document(TF_Idf_Bow2)\n",
    "d3_lenght= Get_lenght_Document(TF_Idf_Bow3)\n",
    "d4_lenght= Get_lenght_Document(TF_Idf_Bow4)\n",
    "d5_lenght= Get_lenght_Document(TF_Idf_Bow5)\n",
    "d6_lenght= Get_lenght_Document(TF_Idf_Bow6)\n",
    "d7_lenght= Get_lenght_Document(TF_Idf_Bow7)\n",
    "d8_lenght= Get_lenght_Document(TF_Idf_Bow8)\n",
    "d9_lenght= Get_lenght_Document(TF_Idf_Bow9)\n",
    "pd.DataFrame([d0_lenght, d1_lenght, d2_lenght, d3_lenght, d4_lenght, d5_lenght, d6_lenght, d7_lenght,\n",
    "              d8_lenght, d9_lenght],columns =['Document_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------normalize the TF_IDF----------------#\n",
    "\n",
    "def Normalize_TF_IDF(TF_Idf_Bow, document_length):\n",
    "    TT_IDF_normalize = {}\n",
    "    for word, val in TF_Idf_Bow.items():\n",
    "        try:\n",
    "            \n",
    "            TT_IDF_normalize[word] = val/document_length\n",
    "        except:\n",
    "            continue\n",
    "    return TT_IDF_normalize\n",
    "\n",
    "TF_IDF_Norm0=Normalize_TF_IDF(TF_Idf_Bow0,d0_lenght)\n",
    "TF_IDF_Norm1=Normalize_TF_IDF(TF_Idf_Bow1,d1_lenght)\n",
    "TF_IDF_Norm2=Normalize_TF_IDF(TF_Idf_Bow2,d2_lenght)\n",
    "TF_IDF_Norm3=Normalize_TF_IDF(TF_Idf_Bow3,d3_lenght)\n",
    "TF_IDF_Norm4=Normalize_TF_IDF(TF_Idf_Bow4,d4_lenght)\n",
    "TF_IDF_Norm5=Normalize_TF_IDF(TF_Idf_Bow5,d5_lenght)\n",
    "TF_IDF_Norm6=Normalize_TF_IDF(TF_Idf_Bow6,d6_lenght)\n",
    "TF_IDF_Norm7=Normalize_TF_IDF(TF_Idf_Bow7,d7_lenght)\n",
    "TF_IDF_Norm8=Normalize_TF_IDF(TF_Idf_Bow8,d8_lenght)\n",
    "TF_IDF_Norm9=Normalize_TF_IDF(TF_Idf_Bow9,d9_lenght)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.508263</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0.728087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.235250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.472707</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603298</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5  \\\n",
       "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "antony     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
       "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
       "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "brutus     0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
       "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
       "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
       "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "mercy      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
       "\n",
       "                  6         7         8         9  \n",
       "rush       0.325248  0.325248  0.359756  0.359756  \n",
       "antony     0.000000  0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
       "brutus     0.000000  0.000000  0.000000  0.000000  \n",
       "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
       "to         0.325248  0.325248  0.359756  0.359756  \n",
       "where      0.325248  0.325248  0.359756  0.359756  \n",
       "caeser     0.000000  0.000000  0.000000  0.000000  \n",
       "fear       0.427365  0.427365  0.000000  0.472707  \n",
       "fool       0.325248  0.325248  0.359756  0.359756  \n",
       "in         0.325248  0.325248  0.359756  0.359756  \n",
       "tread      0.325248  0.325248  0.359756  0.359756  \n",
       "angel      0.427365  0.427365  0.472707  0.000000  \n",
       "mercy      0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------print TF_IDF_Normalization-------------------#\n",
    "pd.DataFrame([TF_IDF_Norm0, TF_IDF_Norm1, TF_IDF_Norm2, TF_IDF_Norm3, TF_IDF_Norm4, TF_IDF_Norm5, TF_IDF_Norm6, TF_IDF_Norm7,\n",
    "              TF_IDF_Norm8, TF_IDF_Norm9]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angel',\n",
       " 'antony',\n",
       " 'brutus',\n",
       " 'caeser',\n",
       " 'calpurnia',\n",
       " 'cleopatra',\n",
       " 'fear',\n",
       " 'fool',\n",
       " 'in',\n",
       " 'mercy',\n",
       " 'rush',\n",
       " 'to',\n",
       " 'tread',\n",
       " 'where',\n",
       " 'worser'}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'fear']\n",
      "[6, 7, 9]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.427365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.427365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.472707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity\n",
       "6    0.427365\n",
       "7    0.427365\n",
       "9    0.472707"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------applay Preprocessing for query ------------#\n",
    "# make preprocessing for query \n",
    "query =\"my name is fear\"      \n",
    "# query_tokens=[]\n",
    "def Preprocessing(word):\n",
    "    word =removePatterns(query)\n",
    "    word = word_tokenize(word.lower())\n",
    "#     word = remove_stop_words(word)    \n",
    "    query_tokens=stemming_lemmitization(word)\n",
    "    return query_tokens\n",
    "\n",
    "query_tokens=Preprocessing(query)\n",
    "print(query_tokens)\n",
    "\n",
    "#------------------intersection with the document -------------#\n",
    "intersectionDocument =[]\n",
    "for token in query_tokens:\n",
    "    \n",
    "    try:\n",
    "        temp=postional_index[token]\n",
    "        for j in temp[1].keys():\n",
    "            intersectionDocument.append(j)   \n",
    "    except:\n",
    "        continue\n",
    "matchedDocument=sorted(set(intersectionDocument))\n",
    "print(matchedDocument)\n",
    "AllNormalizedTD_IDF=[TF_IDF_Norm0, TF_IDF_Norm1, TF_IDF_Norm2, TF_IDF_Norm3,\n",
    "                     TF_IDF_Norm4, TF_IDF_Norm5, TF_IDF_Norm6, TF_IDF_Norm7,\n",
    "                     TF_IDF_Norm8, TF_IDF_Norm9]\n",
    "#------------------compute Tf for Query ------------------#\n",
    "QueryDict = dict.fromkeys(wordSet, 0)\n",
    "for word in wordSet:\n",
    "    for token in query_tokens:\n",
    "        if(token==word):\n",
    "            QueryDict[word]+=1\n",
    "# print(QueryDict)\n",
    "#-----------------compute Tf-w for Query ----------------#\n",
    "for word in wordSet:\n",
    "    if(QueryDict[word]>0):\n",
    "        QueryDict[word]=1+math.log(QueryDict[word],10)\n",
    "\n",
    "#------------------compute TF_IDF for Query -------------#\n",
    "def computeTF_IDF_query(QueryDict, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in QueryDict.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n",
    "TF_IDF_Query =computeTF_IDF_query(QueryDict,idfs)\n",
    "\n",
    "query_length=Get_lenght_Document(TF_IDF_Query)\n",
    "\n",
    "Normalize_TF_IDF_Query= Normalize_TF_IDF(TF_IDF_Query,query_length)\n",
    "\n",
    "\n",
    "\n",
    "def score_Document(Normalize_TF_IDF_Query,TF_IDF_Norm):\n",
    "    score=0;\n",
    "    index=0;\n",
    "    TF_IDF_Query =list(Normalize_TF_IDF_Query.values())\n",
    "    TF_IDF =list(TF_IDF_Norm.values())\n",
    "    for i in range(len(TF_IDF)):\n",
    "        score+=TF_IDF_Query[i]*TF_IDF[i]\n",
    "    \n",
    "    return score\n",
    "#-------------Rank the Document -----------#\n",
    "Rank=[]\n",
    "for i in matchedDocument:\n",
    "    Rank.append(score_Document(Normalize_TF_IDF_Query,AllNormalizedTD_IDF[i]))\n",
    "pd.DataFrame(Rank,columns =[\"Similarity\"],index=matchedDocument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
